{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93MsxxP4sRbk"
   },
   "source": [
    "# Named-entity recognition (NER)\n",
    "\n",
    "+ The goal of NER is to extract spans of named entities in text\n",
    "+ Initially, named entities are persons, locations, organizations\n",
    "+ Usually there are more types: dates, monetary amounts, etc. (e.g. brand names)\n",
    "+ Why? To solve problems of reference, referential selection and coreference, metonymy, which are central to search, question-answering systems, text coherence, syntactic and morphological parsing, etc.\n",
    "+ Difficulties:\n",
    "    - homonymy: \"Washington\" -- city, state, last name, giraffe name, company name?\n",
    "    - technical: what tags? where are the entity boundaries?\n",
    "+ BIOES scheme: a prefix is ​​added to the entity label (e.g. PER for persons or ORG for organizations), which denotes the position of the token in the entity span:\n",
    "    - B – beginning – the first token in the entity span, which consists of several tokens;\n",
    "    - I – inside – inside the span;\n",
    "    - O – outside – the token does not belong to any entity;\n",
    "    - E – ending – the last token of the entity, which consists of several tokens;\n",
    "    - S – single – the entity consists of one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Y5tsneapLqOO"
   },
   "outputs": [],
   "source": [
    "ru_text = '''Вторая нитка \"Северного потока - 2\" заполнена газом, и теперь газопровод полностью готов к эксплуатации. Об этом доложил в среду глава \"Газпрома\" Алексей Миллер президенту РФ Владимиру Путину.\n",
    "\n",
    "Однако это не означает, что газопровод будет запущен в ближайшие дни и даже месяцы, - ранее вице-премьер Александр Новак выражал надежду, что его сертификация завершится к концу первой половины 2022 года. В самой Германии заявляли, что соответствующее решение не будет принято в первом полугодии. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BXX3hghgLp6j"
   },
   "outputs": [],
   "source": [
    "eng_text = '''MOSCOW, Dec 29 (Reuters) - Russian President Vladimir Putin said on Wednesday the Nord Stream 2 undersea gas pipeline would help to calm a surge in European gas prices and was ready to start exports now a second stretch of the pipeline has been filled.\n",
    "\n",
    "Nord Stream 2, completed in September but awaiting regulatory approval from Germany and the European Union, faces resistance from the United States and several countries including Poland and Ukraine, which say it will increase Russia's leverage over Europe.\n",
    "\n",
    "The pipeline had been scheduled to be completed in 2019, but construction was suspended following the threat of sanctions by the U.S. administration of Donald Trump and the subsequent withdrawal of the Swiss-Dutch company Allseas from pipe-laying.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5yy-LvLDW1lC"
   },
   "outputs": [],
   "source": [
    "de_text = '''Der neu gewählte Bundeskanzler Olaf Scholz (SPD) traf am Freitag in Brüssel mit Kommissionspräsidentin Ursula von der Leyen zusammen. Beide richteten warnende Worte an Russland. Von der Leyen sagte: „Wir erwarten, dass Russland deeskaliert und jegliche Art von Aggression gegenüber seinen Nachbarn unterlässt und die Rechte souveräner Staaten achtet. Andernfalls ist die Europäische Union bereit, nicht nur die bestehenden Sanktionen zu verschärfen, sondern auch neue, spürbare Maßnahmen zu ergreifen.“ Die Kommissionspräsidentin nannte die Felder Wirtschaft und Finanzen. '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOhqasSHO9PU"
   },
   "source": [
    "## Stanza\n",
    "\n",
    "+ https://stanfordnlp.github.io/stanza/\n",
    "+ library for NLP\n",
    "+ 66 languages, including Russian\n",
    "+ tokenization, lemmatization, morphological and syntactic parsing, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-2pe9MGFYEMe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.6.1-py3-none-any.whl (881 kB)\n",
      "     -------------------------------------- 881.2/881.2 kB 4.3 MB/s eta 0:00:00\n",
      "Collecting emoji (from stanza)\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "     ------------------------------------- 586.9/586.9 kB 12.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\xiaomi\\appdata\\roaming\\python\\python37\\site-packages (from stanza) (1.21.6)\n",
      "Collecting protobuf>=3.15.0 (from stanza)\n",
      "  Downloading protobuf-4.24.4-cp37-cp37m-win_amd64.whl (430 kB)\n",
      "     ------------------------------------- 430.0/430.0 kB 13.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from stanza) (2.27.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from stanza) (1.13.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from stanza) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Collecting typing-extensions (from torch>=1.3.0->stanza)\n",
      "  Downloading typing_extensions-4.7.1-py3-none-any.whl (33 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from requests->stanza) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from requests->stanza) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from requests->stanza) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (from tqdm->stanza) (0.4.6)\n",
      "Installing collected packages: typing-extensions, protobuf, emoji, stanza\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.9.2\n",
      "    Uninstalling protobuf-3.9.2:\n",
      "      Successfully uninstalled protobuf-3.9.2\n",
      "Successfully installed emoji-2.14.0 protobuf-4.24.4 stanza-1.6.1 typing-extensions-4.4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fake-useragent 1.1.1 requires importlib-resources>=5.0; python_version < \"3.10\", which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n",
      "flask 2.2.5 requires click>=8.0, but you have click 7.1.2 which is incompatible.\n",
      "deeppavlov 0.6.1 requires Cython==0.29.12, but you have cython 0.29.21 which is incompatible.\n",
      "deeppavlov 0.6.1 requires flask==1.1.1, but you have flask 2.2.5 which is incompatible.\n",
      "deeppavlov 0.6.1 requires h5py==2.9.0, but you have h5py 2.10.0 which is incompatible.\n",
      "deeppavlov 0.6.1 requires keras==2.2.4, but you have keras 2.4.3 which is incompatible.\n",
      "deeppavlov 0.6.1 requires numpy==1.16.4, but you have numpy 1.21.6 which is incompatible.\n",
      "deeppavlov 0.6.1 requires overrides==1.9, but you have overrides 3.1.0 which is incompatible.\n",
      "deeppavlov 0.6.1 requires pandas==0.24.2, but you have pandas 1.3.5 which is incompatible.\n",
      "deeppavlov 0.6.1 requires pyopenssl==19.0.0, but you have pyopenssl 22.0.0 which is incompatible.\n",
      "deeppavlov 0.6.1 requires requests==2.22.0, but you have requests 2.27.1 which is incompatible.\n",
      "deeppavlov 0.6.1 requires scikit-learn==0.21.2, but you have scikit-learn 1.0.2 which is incompatible.\n",
      "deeppavlov 0.6.1 requires scipy==1.3.0, but you have scipy 1.7.3 which is incompatible.\n",
      "deeppavlov 0.6.1 requires tqdm==4.32.2, but you have tqdm 4.64.1 which is incompatible.\n",
      "flake8 4.0.1 requires importlib-metadata<4.3; python_version < \"3.8\", but you have importlib-metadata 4.6.4 which is incompatible.\n",
      "spyder 5.2.2 requires pyqt5<5.13, but you have pyqt5 5.15.4 which is incompatible.\n",
      "tensorboard 2.11.2 requires protobuf<4,>=3.9.2, but you have protobuf 4.24.4 which is incompatible.\n",
      "uvicorn 0.9.0 requires h11==0.8.*, but you have h11 0.14.0 which is incompatible.\n",
      "virtualenv 20.0.4 requires importlib-metadata<2,>=0.12; python_version < \"3.8\", but you have importlib-metadata 4.6.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XvJgERasYpaN"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43f36f595754cf2adc31a148268119a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:28:43 INFO: Downloading default packages for language: en (English) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e064b4f5df044914a099208556c1bac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.6.0/models/default.zip:   0%|          | 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:29:10 INFO: Finished downloading models and saved to C:\\Users\\Xiaomi\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmyNmzHVR9lE"
   },
   "source": [
    "To find named entities, one needs to tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "yt-MXpZuLdLu"
   },
   "outputs": [],
   "source": [
    "def stanza_nlp(text):\n",
    "    nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "    print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MHlvT6CoLgfc",
    "outputId": "53f22e39-fc92-48fb-8a3b-fa966b17556b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:29:19 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87434287c8d34353912c800621e2a473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:29:20 INFO: Loading these models for language: en (English):\n",
      "================================\n",
      "| Processor | Package          |\n",
      "--------------------------------\n",
      "| tokenize  | combined         |\n",
      "| ner       | ontonotes_charlm |\n",
      "================================\n",
      "\n",
      "2024-11-27 13:29:20 INFO: Using device: cpu\n",
      "2024-11-27 13:29:20 INFO: Loading: tokenize\n",
      "2024-11-27 13:29:20 INFO: Loading: ner\n",
      "2024-11-27 13:29:20 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: MOSCOW\ttype: GPE\n",
      "entity: Dec 29 (Reuters) -\ttype: DATE\n",
      "entity: Russian\ttype: NORP\n",
      "entity: Vladimir Putin\ttype: PERSON\n",
      "entity: Wednesday\ttype: DATE\n",
      "entity: 2\ttype: CARDINAL\n",
      "entity: European\ttype: NORP\n",
      "entity: second\ttype: ORDINAL\n",
      "entity: Nord Stream 2\ttype: ORG\n",
      "entity: September\ttype: DATE\n",
      "entity: Germany\ttype: GPE\n",
      "entity: the European Union\ttype: ORG\n",
      "entity: the United States\ttype: GPE\n",
      "entity: Poland\ttype: GPE\n",
      "entity: Ukraine\ttype: GPE\n",
      "entity: Russia\ttype: GPE\n",
      "entity: Europe\ttype: LOC\n",
      "entity: 2019\ttype: DATE\n",
      "entity: U.S.\ttype: GPE\n",
      "entity: Donald Trump\ttype: PERSON\n",
      "entity: Swiss\ttype: NORP\n",
      "entity: Allseas\ttype: ORG\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp(eng_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BNmwxy8Ur_w"
   },
   "source": [
    "To get BIOES NER tags for each token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6SsRTz7UTQY",
    "outputId": "2a3aa18d-a405-4f3c-be1e-b2917c281973"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:29:44 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074e0930a7b3459e9b3f503122d9286e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:29:45 INFO: Loading these models for language: en (English):\n",
      "================================\n",
      "| Processor | Package          |\n",
      "--------------------------------\n",
      "| tokenize  | combined         |\n",
      "| ner       | ontonotes_charlm |\n",
      "================================\n",
      "\n",
      "2024-11-27 13:29:45 INFO: Using device: cpu\n",
      "2024-11-27 13:29:45 INFO: Loading: tokenize\n",
      "2024-11-27 13:29:45 INFO: Loading: ner\n",
      "2024-11-27 13:29:46 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token: Vladimir\tner: B-PERSON\n",
      "token: Putin\tner: E-PERSON\n",
      "token: said\tner: O\n",
      "token: on\tner: O\n",
      "token: Wednesday\tner: S-DATE\n",
      "token: the\tner: O\n",
      "token: Nord\tner: O\n",
      "token: Stream\tner: O\n",
      "token: 2\tner: S-CARDINAL\n",
      "token: undersea\tner: O\n",
      "token: gas\tner: O\n",
      "token: pipeline\tner: O\n",
      "token: would\tner: O\n",
      "token: help\tner: O\n",
      "token: to\tner: O\n",
      "token: calm\tner: O\n",
      "token: a\tner: O\n",
      "token: surge\tner: O\n",
      "token: in\tner: O\n",
      "token: European\tner: S-NORP\n",
      "token: gas\tner: O\n",
      "token: prices\tner: O\n",
      "token: and\tner: O\n",
      "token: was\tner: O\n",
      "token: ready\tner: O\n",
      "token: to\tner: O\n",
      "token: start\tner: O\n",
      "token: exports\tner: O\n",
      "token: now\tner: O\n",
      "token: a\tner: O\n",
      "token: second\tner: S-ORDINAL\n",
      "token: stretch\tner: O\n",
      "token: of\tner: O\n",
      "token: the\tner: O\n",
      "token: pipeline\tner: O\n",
      "token: has\tner: O\n",
      "token: been\tner: O\n",
      "token: filled\tner: O\n",
      "token: .\tner: O\n",
      "token: Nord\tner: B-ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "doc = nlp(eng_text)\n",
    "print(*[f'token: {token.text}\\tner: {token.ner}' for sent in doc.sentences for token in sent.tokens][10:50], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X3S-u6_QYMaa"
   },
   "source": [
    "Let's test on Russian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SjrnlVgaYvDi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c369052722094c86b4f410463258f184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:31:42 INFO: Downloading default packages for language: ru (Russian) ...\n",
      "2024-11-27 13:31:45 INFO: File exists: C:\\Users\\Xiaomi\\stanza_resources\\ru\\default.zip\n",
      "2024-11-27 13:31:56 INFO: Finished downloading models and saved to C:\\Users\\Xiaomi\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "stanza.download('ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "D1liHoU9NfUQ"
   },
   "outputs": [],
   "source": [
    "def stanza_nlp_ru(text):\n",
    "    nlp = stanza.Pipeline(lang='ru', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "    print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0B_m8aKNg-X",
    "outputId": "f4bd0a7d-7231-4d49-ac13-984caf56ad9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:31:56 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcba555164bc4ff5bf87234dfd9208c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:31:57 INFO: Loading these models for language: ru (Russian):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | syntagrus |\n",
      "| ner       | wikiner   |\n",
      "=========================\n",
      "\n",
      "2024-11-27 13:31:57 INFO: Using device: cpu\n",
      "2024-11-27 13:31:57 INFO: Loading: tokenize\n",
      "2024-11-27 13:31:57 INFO: Loading: ner\n",
      "2024-11-27 13:31:59 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Северного потока - 2\ttype: MISC\n",
      "entity: Газпрома\ttype: ORG\n",
      "entity: Алексей Миллер\ttype: PER\n",
      "entity: РФ\ttype: LOC\n",
      "entity: Владимиру Путину\ttype: PER\n",
      "entity: Александр Новак\ttype: PER\n",
      "entity: Германии\ttype: LOC\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp_ru(ru_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6l__koYWYRTl"
   },
   "source": [
    "Choose a language that interests you and test stanza in it, what problems of identifying named entities are specific to the language you have chosen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kO7ax_jeXtJ8",
    "outputId": "ee86a0bf-aba4-4ce0-d77f-fe0c4fe6ca08"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:33:24 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9589f49e8314dff81585d1689bcf466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:33:24 WARNING: Language de package default expects mwt, which has been added\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9331423c3a94743a552cb95c8c9ac54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/tokenize/gsd.pt:   0%|         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d14b744c80f41f993d0d3f5f4528155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/mwt/gsd.pt:   0%|          | 0.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c98849dc02046f59086ab72df092f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/ner/germeval2014.pt:   0%|     …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666eb6f52a074deea9618b311f0c5fad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/pretrain/fasttextwiki.pt:   0%|…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0795c07228094e63ac72457502fb8d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/backward_charlm/newswiki.pt:   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8f7e3bab404718869b84d914c05ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-de/resolve/v1.6.0/models/forward_charlm/newswiki.pt:   0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 13:33:39 INFO: Loading these models for language: de (German):\n",
      "============================\n",
      "| Processor | Package      |\n",
      "----------------------------\n",
      "| tokenize  | gsd          |\n",
      "| mwt       | gsd          |\n",
      "| ner       | germeval2014 |\n",
      "============================\n",
      "\n",
      "2024-11-27 13:33:39 INFO: Using device: cpu\n",
      "2024-11-27 13:33:39 INFO: Loading: tokenize\n",
      "2024-11-27 13:33:39 INFO: Loading: mwt\n",
      "2024-11-27 13:33:39 INFO: Loading: ner\n",
      "2024-11-27 13:33:41 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Olaf Scholz\ttype: PER\n",
      "entity: SPD\ttype: ORG\n",
      "entity: Brüssel\ttype: LOC\n",
      "entity: Ursula von der Leyen\ttype: PER\n",
      "entity: Russland\ttype: LOC\n",
      "entity: Von der Leyen\ttype: PER\n",
      "entity: Russland\ttype: LOC\n",
      "entity: Europäische Union\ttype: ORG\n"
     ]
    }
   ],
   "source": [
    "def stanza_nlp_de(text):\n",
    "    nlp = stanza.Pipeline(lang='de', processors='tokenize,ner')\n",
    "    doc = nlp(text)\n",
    "    print(*[f'entity: {ent.text}\\ttype: {ent.type}' for sent in doc.sentences for ent in sent.ents], sep='\\n')\n",
    "stanza_nlp_de(de_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu4KUNQzbGlH"
   },
   "source": [
    "## SpaCy\n",
    "\n",
    "+ Library for advanced NLP\n",
    "+ A number of languages, English, Chinese, German, French, Italian, Polish, Spanish, etc., models are being developed for more languages\n",
    "+ About spaCy: https://spacy.io/usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "h28AmaSUhFld"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (22.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 7.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (67.1.0)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "     ------------------------------------- 804.0/804.0 kB 16.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (0.37.1)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.4/65.4 kB 3.4 MB/s eta 0:00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\Xiaomi\\Anaconda3\\python.exe -m pip install -U pip setuptools wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\xiaomi\\anaconda3\\lib\\site-packages (2.1.9)\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.8.2.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 1.3/1.3 MB 6.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [107 lines of output]\n",
      "  Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "  Collecting setuptools\n",
      "    Using cached setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "  Collecting cython<3.0,>=0.25\n",
      "    Downloading Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "       -------------------------------------- 989.5/989.5 kB 5.2 MB/s eta 0:00:00\n",
      "  Collecting cymem<2.1.0,>=2.0.2\n",
      "    Downloading cymem-2.0.10.tar.gz (10 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Installing backend dependencies: started\n",
      "    Installing backend dependencies: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting preshed<3.1.0,>=3.0.2\n",
      "    Downloading preshed-3.0.9-cp37-cp37m-win_amd64.whl (122 kB)\n",
      "       -------------------------------------- 122.6/122.6 kB 7.5 MB/s eta 0:00:00\n",
      "  Collecting murmurhash<1.1.0,>=0.28.0\n",
      "    Downloading murmurhash-1.0.11.tar.gz (13 kB)\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'done'\n",
      "    Getting requirements to build wheel: started\n",
      "    Getting requirements to build wheel: finished with status 'done'\n",
      "    Installing backend dependencies: started\n",
      "    Installing backend dependencies: finished with status 'done'\n",
      "    Preparing metadata (pyproject.toml): started\n",
      "    Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Collecting thinc<8.4.0,>=8.3.0\n",
      "    Downloading thinc-8.3.2.tar.gz (193 kB)\n",
      "       ------------------------------------- 193.9/193.9 kB 11.5 MB/s eta 0:00:00\n",
      "    Installing build dependencies: started\n",
      "    Installing build dependencies: finished with status 'error'\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    pip subprocess to install build dependencies did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    [56 lines of output]\n",
      "    Ignoring numpy: markers 'python_version >= \"3.9\"' don't match your environment\n",
      "    Collecting setuptools\n",
      "      Using cached setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "    Collecting cython<3.0,>=0.25\n",
      "      Using cached Cython-0.29.37-py2.py3-none-any.whl (989 kB)\n",
      "    Collecting murmurhash<1.1.0,>=1.0.2\n",
      "      Using cached murmurhash-1.0.11.tar.gz (13 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "      Installing backend dependencies: started\n",
      "      Installing backend dependencies: finished with status 'done'\n",
      "      Preparing metadata (pyproject.toml): started\n",
      "      Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "    Collecting cymem<2.1.0,>=2.0.2\n",
      "      Using cached cymem-2.0.10.tar.gz (10 kB)\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'done'\n",
      "      Getting requirements to build wheel: started\n",
      "      Getting requirements to build wheel: finished with status 'done'\n",
      "      Installing backend dependencies: started\n",
      "      Installing backend dependencies: finished with status 'done'\n",
      "      Preparing metadata (pyproject.toml): started\n",
      "      Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "    Collecting preshed<3.1.0,>=3.0.2\n",
      "      Using cached preshed-3.0.9-cp37-cp37m-win_amd64.whl (122 kB)\n",
      "    Collecting blis<1.1.0,>=1.0.0\n",
      "      Downloading blis-1.0.1.tar.gz (3.6 MB)\n",
      "         ---------------------------------------- 3.6/3.6 MB 10.9 MB/s eta 0:00:00\n",
      "      Installing build dependencies: started\n",
      "      Installing build dependencies: finished with status 'error'\n",
      "      error: subprocess-exited-with-error\n",
      "  \n",
      "      pip subprocess to install build dependencies did not run successfully.\n",
      "      exit code: 1\n",
      "  \n",
      "      [7 lines of output]\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-68.0.0-py3-none-any.whl (804 kB)\n",
      "      Collecting cython>=0.25\n",
      "        Using cached Cython-3.0.11-cp37-cp37m-win_amd64.whl (2.7 MB)\n",
      "      ERROR: Ignored the following versions that require a different python version: 1.22.0 Requires-Python >=3.8; 1.22.1 Requires-Python >=3.8; 1.22.2 Requires-Python >=3.8; 1.22.3 Requires-Python >=3.8; 1.22.4 Requires-Python >=3.8; 1.23.0 Requires-Python >=3.8; 1.23.1 Requires-Python >=3.8; 1.23.2 Requires-Python >=3.8; 1.23.3 Requires-Python >=3.8; 1.23.4 Requires-Python >=3.8; 1.23.5 Requires-Python >=3.8; 1.24.0 Requires-Python >=3.8; 1.24.1 Requires-Python >=3.8; 1.24.2 Requires-Python >=3.8; 1.24.3 Requires-Python >=3.8; 1.24.4 Requires-Python >=3.8; 1.25.0 Requires-Python >=3.9; 1.25.1 Requires-Python >=3.9; 1.25.2 Requires-Python >=3.9; 1.26.0 Requires-Python <3.13,>=3.9; 1.26.1 Requires-Python <3.13,>=3.9; 1.26.2 Requires-Python >=3.9; 1.26.3 Requires-Python >=3.9; 1.26.4 Requires-Python >=3.9; 2.0.0 Requires-Python >=3.9; 2.0.1 Requires-Python >=3.9; 2.0.2 Requires-Python >=3.9; 2.1.0 Requires-Python >=3.10; 2.1.0rc1 Requires-Python >=3.10; 2.1.1 Requires-Python >=3.10; 2.1.2 Requires-Python >=3.10; 2.1.3 Requires-Python >=3.10; 2.2.0rc1 Requires-Python >=3.10; 3.1.0a1 Requires-Python >=3.8; 68.1.0 Requires-Python >=3.8; 68.1.2 Requires-Python >=3.8; 68.2.0 Requires-Python >=3.8; 68.2.1 Requires-Python >=3.8; 68.2.2 Requires-Python >=3.8; 69.0.0 Requires-Python >=3.8; 69.0.1 Requires-Python >=3.8; 69.0.2 Requires-Python >=3.8; 69.0.3 Requires-Python >=3.8; 69.1.0 Requires-Python >=3.8; 69.1.1 Requires-Python >=3.8; 69.2.0 Requires-Python >=3.8; 69.3 Requires-Python >=3.8; 69.3.0 Requires-Python >=3.8; 69.3.1 Requires-Python >=3.8; 69.4 Requires-Python >=3.8; 69.4.0 Requires-Python >=3.8; 69.4.1 Requires-Python >=3.8; 69.4.2 Requires-Python >=3.8; 69.5.0 Requires-Python >=3.8; 69.5.1 Requires-Python >=3.8; 70.0.0 Requires-Python >=3.8; 70.1.0 Requires-Python >=3.8; 70.1.1 Requires-Python >=3.8; 70.2.0 Requires-Python >=3.8; 70.3.0 Requires-Python >=3.8; 71.0.0 Requires-Python >=3.8; 71.0.1 Requires-Python >=3.8; 71.0.2 Requires-Python >=3.8; 71.0.3 Requires-Python >=3.8; 71.0.4 Requires-Python >=3.8; 71.1.0 Requires-Python >=3.8; 72.0.0 Requires-Python >=3.8; 72.1.0 Requires-Python >=3.8; 72.2.0 Requires-Python >=3.8; 73.0.0 Requires-Python >=3.8; 73.0.1 Requires-Python >=3.8; 74.0.0 Requires-Python >=3.8; 74.1.0 Requires-Python >=3.8; 74.1.1 Requires-Python >=3.8; 74.1.2 Requires-Python >=3.8; 74.1.3 Requires-Python >=3.8; 75.0.0 Requires-Python >=3.8; 75.1.0 Requires-Python >=3.8; 75.2.0 Requires-Python >=3.8; 75.3.0 Requires-Python >=3.8; 75.4.0 Requires-Python >=3.9; 75.5.0 Requires-Python >=3.9; 75.6.0 Requires-Python >=3.9\n",
      "      ERROR: Could not find a version that satisfies the requirement numpy<3.0.0,>=2.0.0 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.21.2, 1.21.3, 1.21.4, 1.21.5, 1.21.6)\n",
      "      ERROR: No matching distribution found for numpy<3.0.0,>=2.0.0\n",
      "      [end of output]\n",
      "  \n",
      "      note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "    error: subprocess-exited-with-error\n",
      "  \n",
      "    pip subprocess to install build dependencies did not run successfully.\n",
      "    exit code: 1\n",
      "  \n",
      "    See above for output.\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "    [end of output]\n",
      "  \n",
      "    note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  pip subprocess to install build dependencies did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "pip subprocess to install build dependencies did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
      "     --------------------------------------- 11.1/11.1 MB 31.1 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: en_core_web_sm\n",
      "  Building wheel for en_core_web_sm (setup.py): started\n",
      "  Building wheel for en_core_web_sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en_core_web_sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074412 sha256=4d16352d6a106e4ff00efccf922b77a5065efe0ad18bcdeb6995f276003689f0\n",
      "  Stored in directory: C:\\Users\\Xiaomi\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-1134zopl\\wheels\\59\\4f\\8c\\0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
      "Successfully built en_core_web_sm\n",
      "Installing collected packages: en_core_web_sm\n",
      "Successfully installed en_core_web_sm-2.1.0\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\n"
     ]
    }
   ],
   "source": [
    "!pip install -U pip setuptools wheel\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rvWhTNwpbuNk"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13276\\3164261673.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"en_core_web_sm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(name, **overrides)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"exists\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Path or Path-like to model data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_3mzWe4b02P",
    "outputId": "05263070-5080-424e-98f4-b52605f47973"
   },
   "outputs": [],
   "source": [
    "doc = nlp(eng_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "or0DoLYHdoj6"
   },
   "source": [
    "SpaCy offers 18 tags (see the list [here](https://towardsdatascience.com/named-entity-recognition-ner-using-spacy-nlp-part-4-28da2ece57c6)) for different types of named entities, you can add your custom tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WF4KTyZBb9la",
    "outputId": "a518aedc-c0f8-4b6c-eed1-7a941220e16c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before [('MOSCOW', 0, 6, 'GPE'), ('Dec 29', 8, 14, 'DATE'), ('Reuters', 16, 23, 'ORG'), ('Russian', 27, 34, 'NORP'), ('Vladimir Putin', 45, 59, 'PERSON'), ('Wednesday', 68, 77, 'DATE'), ('2', 94, 95, 'CARDINAL'), ('European', 148, 156, 'NORP'), ('second', 205, 211, 'ORDINAL'), ('September', 282, 291, 'DATE'), ('Germany', 330, 337, 'GPE'), ('the European Union', 342, 360, 'ORG'), ('the United States', 384, 401, 'GPE'), ('Poland', 434, 440, 'GPE'), ('Ukraine', 445, 452, 'GPE'), ('Russia', 481, 487, 'GPE'), ('Europe', 504, 510, 'LOC'), ('2019', 564, 568, 'DATE'), ('U.S.', 642, 646, 'GPE'), ('Donald Trump', 665, 677, 'PERSON'), ('Swiss', 715, 720, 'NORP')]\n",
      "After [('MOSCOW', 0, 6, 'GPE'), ('Dec 29', 8, 14, 'DATE'), ('Reuters', 16, 23, 'ORG'), ('Russian', 27, 34, 'NORP'), ('Vladimir Putin', 45, 59, 'PERSON'), ('Wednesday', 68, 77, 'DATE'), ('Nord Stream', 82, 93, 'OBJ'), ('2', 94, 95, 'CARDINAL'), ('European', 148, 156, 'NORP'), ('second', 205, 211, 'ORDINAL'), ('September', 282, 291, 'DATE'), ('Germany', 330, 337, 'GPE'), ('the European Union', 342, 360, 'ORG'), ('the United States', 384, 401, 'GPE'), ('Poland', 434, 440, 'GPE'), ('Ukraine', 445, 452, 'GPE'), ('Russia', 481, 487, 'GPE'), ('Europe', 504, 510, 'LOC'), ('2019', 564, 568, 'DATE'), ('U.S.', 642, 646, 'GPE'), ('Donald Trump', 665, 677, 'PERSON'), ('Swiss', 715, 720, 'NORP')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(eng_text)\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('Before', ents)\n",
    "# the model didn't recognize \"Nord Stream\" as an entity :(\n",
    "\n",
    "ns2_ent = Span(doc, 16, 18, label=\"OBJ\") # create a Span for the new entity, OBJ = object\n",
    "doc.ents = list(doc.ents) + [ns2_ent]\n",
    "\n",
    "ents = [(e.text, e.start_char, e.end_char, e.label_) for e in doc.ents]\n",
    "print('After', ents)\n",
    "#('Nord Stream', 82, 93, 'OBJ') got recognized as an object entity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFnkVInYezEf",
    "outputId": "81a2c6c2-2636-4e09-f0f2-4c6f39bc6e05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ent for ent in doc.ents if ent.label_ == 'OBJ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "BtQ5iPtPfW4L"
   },
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "wKUuIvTzfihx",
    "outputId": "0a72d6c4-7b02-4df9-a539-dd0e1071f031"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MOSCOW\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Dec 29\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Reuters\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") - \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " President \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Vladimir Putin\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " said on \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wednesday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " the \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Nord Stream\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">OBJ</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " undersea gas pipeline would help to calm a surge in \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    European\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       " gas prices and was ready to start exports now a \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    second\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
       "</mark>\n",
       " stretch of the pipeline has been filled.</br></br>Nord Stream 2, completed in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    September\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " but awaiting regulatory approval from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Germany\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the European Union\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", faces resistance from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the United States\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and several countries including \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Poland\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Ukraine\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", which say it will increase \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Russia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       "'s leverage over \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Europe\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</br></br>The pipeline had been scheduled to be completed in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    2019\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", but construction was suspended following the threat of sanctions by the \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.S.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " administration of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Donald Trump\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and the subsequent withdrawal of the \n",
       "<mark class=\"entity\" style=\"background: #c887fb; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Swiss\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NORP</span>\n",
       "</mark>\n",
       "-Dutch company Allseas from pipe-laying.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = \"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3T4t_57g55_"
   },
   "source": [
    "Let's test in Russian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RL9pPXP2g_uA"
   },
   "outputs": [],
   "source": [
    "! python -m spacy download ru_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "HR53HsdGgal-"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"ru_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gh6csA92ge18",
    "outputId": "93f62313-851d-4af4-c835-c5dea9f2bfec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Газпрома 136 144 ORG\n",
      "Алексей Миллер 146 160 PER\n",
      "РФ 172 174 LOC\n",
      "Владимиру Путину 175 191 PER\n",
      "Александр Новак 299 314 PER\n",
      "Германии 407 415 LOC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(ru_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "5yMLPJyggw38",
    "outputId": "4e4b1c37-4a4f-4190-8252-51ff5e06d8d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Вторая нитка &quot;Северного потока - 2&quot; заполнена газом, и теперь газопровод полностью готов к эксплуатации. Об этом доложил в среду глава &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Газпрома\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Алексей Миллер\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " президенту \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РФ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Владимиру Путину\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>Однако это не означает, что газопровод будет запущен в ближайшие дни и даже месяцы, - ранее вице-премьер \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Александр Новак\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " выражал надежду, что его сертификация завершится к концу первой половины 2022 года. В самой \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Германии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " заявляли, что соответствующее решение не будет принято в первом полугодии. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = \"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un30GRSvh8tq"
   },
   "source": [
    "We may color only certain types of NE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 192
    },
    "id": "kT3h6flWha09",
    "outputId": "c945a13b-bc3e-4c81-ab82-7fbf354c885b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Вторая нитка &quot;Северного потока - 2&quot; заполнена газом, и теперь газопровод полностью готов к эксплуатации. Об этом доложил в среду глава &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Газпрома\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot; Алексей Миллер президенту \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РФ\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " Владимиру Путину.</br></br>Однако это не означает, что газопровод будет запущен в ближайшие дни и даже месяцы, - ранее вице-премьер Александр Новак выражал надежду, что его сертификация завершится к концу первой половины 2022 года. В самой \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Германии\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " заявляли, что соответствующее решение не будет принято в первом полугодии. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'ents':['ORG','LOC']}\n",
    "displacy.render(doc, style = \"ent\", jupyter=True, options=options)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zLegDVZIi81W"
   },
   "source": [
    "Does Spacy work fine on the language of your choice? Are there problems with NER? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fO9vXZPVjJk_"
   },
   "outputs": [],
   "source": [
    "! python -m spacy download de_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "fK-k38GRivV1"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YhcOP-1Ti085",
    "outputId": "a838081c-7e54-4601-d7f3-32ffcdab160d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olaf Scholz 31 42 PER\n",
      "Brüssel 68 75 LOC\n",
      "Ursula 103 109 PER\n",
      "Leyen 118 123 LOC\n",
      "Russland. 168 177 MISC\n",
      "Leyen 186 191 LOC\n",
      "Russland 219 227 LOC\n",
      "Staaten 335 342 LOC\n",
      "Europäische Union 371 388 ORG\n",
      "Die Kommissionspräsidentin 503 529 MISC\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(de_text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9aI-6TXkw25"
   },
   "source": [
    "## Natasha\n",
    "\n",
    "+ Previously, the Natasha library solved the NER problem for the Russian language, was built on the rules\n",
    "+ now it is a full-fledged NLP project for the Russian language\n",
    "+ tokenization, lemmatization, parsing, NER tagging, etc.\n",
    "+ https://github.com/natasha/natasha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmFzxue1ofOp"
   },
   "outputs": [],
   "source": [
    "!pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "_5PxfOaelo9i"
   },
   "outputs": [],
   "source": [
    "from natasha import (\n",
    "    Segmenter,\n",
    "    MorphVocab,\n",
    "\n",
    "    NewsEmbedding,\n",
    "    NewsMorphTagger,\n",
    "    NewsSyntaxParser,\n",
    "    NewsNERTagger,\n",
    "\n",
    "    PER,\n",
    "    NamesExtractor,\n",
    "\n",
    "    Doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "J0BJ07Gqlqx3"
   },
   "outputs": [],
   "source": [
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "syntax_parser = NewsSyntaxParser(emb)\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "doc = Doc(ru_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0buSAEkQooPt"
   },
   "source": [
    "NER depends on segmentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVTa-Rlvmd4e",
    "outputId": "eea810a9-2928-40c7-a579-e9ce66fd0d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DocToken(stop=6, text='Вторая'), DocToken(start=7, stop=12, text='нитка'), DocToken(start=13, stop=14, text='\"'), DocToken(start=14, stop=23, text='Северного'), DocToken(start=24, stop=30, text='потока')]\n",
      "[DocSent(stop=104, text='Вторая нитка \"Северного потока - 2\" заполнена газ..., tokens=[...]), DocSent(start=105, stop=192, text='Об этом доложил в среду глава \"Газпрома\" Алексей ..., tokens=[...]), DocSent(start=194, stop=398, text='Однако это не означает, что газопровод будет запу..., tokens=[...]), DocSent(start=399, stop=490, text='В самой Германии заявляли, что соответствующее ре..., tokens=[...])]\n"
     ]
    }
   ],
   "source": [
    "doc.segment(segmenter)\n",
    "print(doc.tokens[:5])\n",
    "print(doc.sents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "id": "3dOIKw6KmKy3",
    "outputId": "b78a778c-466a-4ed9-c282-aa21b8a7ca48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocSpan(start=136, stop=144, type='ORG', text='Газпрома', tokens=[...]),\n",
       " DocSpan(start=146, stop=160, type='PER', text='Алексей Миллер', tokens=[...]),\n",
       " DocSpan(start=172, stop=174, type='LOC', text='РФ', tokens=[...]),\n",
       " DocSpan(start=175, stop=191, type='PER', text='Владимиру Путину', tokens=[...]),\n",
       " DocSpan(start=299, stop=314, type='PER', text='Александр Новак', tokens=[...]),\n",
       " DocSpan(start=407, stop=415, type='LOC', text='Германии', tokens=[...])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вторая нитка \"Северного потока - 2\" заполнена газом, и теперь \n",
      "газопровод полностью готов к эксплуатации. Об этом доложил в среду \n",
      "глава \"Газпрома\" Алексей Миллер президенту РФ Владимиру Путину.\n",
      "       ORG─────  PER───────────            LO PER───────────── \n",
      "Однако это не означает, что газопровод будет запущен в ближайшие дни и\n",
      " даже месяцы, - ранее вице-премьер Александр Новак выражал надежду, \n",
      "                                   PER────────────                  \n",
      "что его сертификация завершится к концу первой половины 2022 года. В \n",
      "самой Германии заявляли, что соответствующее решение не будет принято \n",
      "      LOC─────                                                        \n",
      "в первом полугодии. \n"
     ]
    }
   ],
   "source": [
    "doc.tag_ner(ner_tagger)\n",
    "display(doc.spans)\n",
    "doc.ner.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYpMB3mhovPD"
   },
   "source": [
    "It is possible to bring entities to normal form, for this it is necessary to carry out morphological analysis and lemmatization (Natasha uses Pymorphy2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cg3uZdhHnu_B",
    "outputId": "cea92313-c35d-416e-c20f-89282ac712f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Вторая ADJ|Case=Nom|Degree=Pos|Gender=Fem|Number=Sing\n",
      "               нитка NOUN|Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing\n",
      "                   \" PUNCT\n",
      "           Северного ADJ|Case=Gen|Degree=Pos|Gender=Masc|Number=Sing\n",
      "              потока NOUN|Animacy=Inan|Case=Gen|Gender=Masc|Number=Sing\n",
      "                   - PUNCT\n",
      "                   2 NUM\n",
      "                   \" PUNCT\n",
      "           заполнена VERB|Aspect=Perf|Gender=Fem|Number=Sing|Tense=Past|Variant=Short|VerbForm=Part|Voice=Pass\n",
      "               газом NOUN|Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing\n",
      "                   , PUNCT\n",
      "                   и CCONJ\n",
      "              теперь ADV|Degree=Pos\n",
      "          газопровод NOUN|Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing\n",
      "           полностью ADV|Degree=Pos\n",
      "               готов ADJ|Degree=Pos|Gender=Masc|Number=Sing|Variant=Short\n",
      "                   к ADP\n",
      "        эксплуатации NOUN|Animacy=Inan|Case=Dat|Gender=Fem|Number=Sing\n",
      "                   . PUNCT\n"
     ]
    }
   ],
   "source": [
    "doc.tag_morph(morph_tagger)\n",
    "doc.sents[0].morph.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Isn2AwZAoD2s",
    "outputId": "27c49e30-4e4a-4bf8-d577-835d7851587e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"': '\"',\n",
       " ',': ',',\n",
       " '-': '-',\n",
       " '.': '.',\n",
       " '2': '2',\n",
       " '2022': '2022',\n",
       " 'Александр': 'александр',\n",
       " 'Алексей': 'алексей',\n",
       " 'В': 'в',\n",
       " 'Владимиру': 'владимир',\n",
       " 'Вторая': 'второй',\n",
       " 'Газпрома': 'газпром',\n",
       " 'Германии': 'германия',\n",
       " 'Миллер': 'миллер',\n",
       " 'Новак': 'новак',\n",
       " 'Об': 'о',\n",
       " 'Однако': 'однако',\n",
       " 'Путину': 'путин',\n",
       " 'РФ': 'рф',\n",
       " 'Северного': 'северный',\n",
       " 'ближайшие': 'близкий',\n",
       " 'будет': 'быть',\n",
       " 'в': 'в',\n",
       " 'вице-премьер': 'вице-премьер',\n",
       " 'выражал': 'выражать',\n",
       " 'газом': 'газ',\n",
       " 'газопровод': 'газопровод',\n",
       " 'глава': 'глава',\n",
       " 'года': 'год',\n",
       " 'готов': 'готовый',\n",
       " 'даже': 'даже',\n",
       " 'дни': 'день',\n",
       " 'доложил': 'доложить',\n",
       " 'его': 'его',\n",
       " 'завершится': 'завершиться',\n",
       " 'заполнена': 'заполнить',\n",
       " 'запущен': 'запустить',\n",
       " 'заявляли': 'заявлять',\n",
       " 'и': 'и',\n",
       " 'к': 'к',\n",
       " 'концу': 'конец',\n",
       " 'месяцы': 'месяц',\n",
       " 'надежду': 'надежда',\n",
       " 'не': 'не',\n",
       " 'нитка': 'нитка',\n",
       " 'означает': 'означать',\n",
       " 'первой': 'первый',\n",
       " 'первом': 'первый',\n",
       " 'полностью': 'полностью',\n",
       " 'половины': 'половина',\n",
       " 'полугодии': 'полугодие',\n",
       " 'потока': 'поток',\n",
       " 'президенту': 'президент',\n",
       " 'принято': 'принять',\n",
       " 'ранее': 'ранее',\n",
       " 'решение': 'решение',\n",
       " 'самой': 'сам',\n",
       " 'сертификация': 'сертификация',\n",
       " 'соответствующее': 'соответствующий',\n",
       " 'среду': 'среда',\n",
       " 'теперь': 'теперь',\n",
       " 'что': 'что',\n",
       " 'эксплуатации': 'эксплуатация',\n",
       " 'это': 'это',\n",
       " 'этом': 'это'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "    \n",
    "{_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uKwOONNo6V5"
   },
   "source": [
    "Приводим сущности к нормальной форме:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Ob-EuREncBl",
    "outputId": "1430a4e2-99cb-449a-db2b-b337dd422c26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Владимиру Путину': 'Владимир Путин',\n",
       " 'Газпрома': 'Газпром',\n",
       " 'Германии': 'Германия'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for span in doc.spans:\n",
    "    span.normalize(morph_vocab)\n",
    "\n",
    "{_.text: _.normal for _ in doc.spans if _.text != _.normal}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "upEkD8V4pivy"
   },
   "source": [
    "Можно извлечь для нормированных имен отдельно имена и фамилии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ackLmRB0oRss",
    "outputId": "049bc571-7e13-46af-bb0d-5c2dba5198fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Александр Новак': {'first': 'Александр'},\n",
       " 'Алексей Миллер': {'first': 'Алексей', 'last': 'Миллер'},\n",
       " 'Владимир Путин': {'first': 'Владимир', 'last': 'Путин'}}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for span in doc.spans:\n",
    "    if span.type == PER:\n",
    "        span.extract_fact(names_extractor)\n",
    "\n",
    "{_.normal: _.fact.as_dict for _ in doc.spans if _.type == PER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "CIu66ktDrUCN"
   },
   "outputs": [],
   "source": [
    "#names_extractor = NamesExtractor(morph_vocab)\n",
    "#dates_extractor = DatesExtractor(morph_vocab)\n",
    "#money_extractor = MoneyExtractor(morph_vocab)\n",
    "#addr_extractor = AddrExtractor(morph_vocab)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
