{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Web Scraping Using BeautifulSoup\n",
    "\n",
    "(https://www.dataquest.io/blog/web-scraping-tutorial-python/)\n",
    "\n",
    "When performing data science tasks, it's common to want to use data found on the internet. You'll usually be able to access this data in csv format, or via an Application Programming Interface (API). However, there are times when the data you want can only be accessed as part of a web page. In cases like this, you'll want to use a technique called web scraping to get the data from the web page into a format you can work with in your analysis.\n",
    "\n",
    "We'll be performing web scraping using the BeautifulSoup library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The components of a web page\n",
    "\n",
    "When we visit a web page, our web browser makes a request to a web server. This request is called a `GET` request, since we're getting files from the server. The server then sends back files that tell our browser how to render the page for us. The files fall into a few main types:\n",
    "\n",
    "+ HTML — contain the main content of the page.\n",
    "+ CSS — add styling to make the page look nicer.\n",
    "+ JS — Javascript files add interactivity to web pages.\n",
    "+ Images — image formats, such as JPG and PNG allow web pages to show pictures.\n",
    "\n",
    "After our browser receives all the files, it renders the page and displays it to us. There's a lot that happens behind the scenes to render a page nicely, but we don't need to worry about most of it when we're web scraping. When we perform web scraping, we're interested in the main content of the web page, so we look at the HTML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML\n",
    "\n",
    "HyperText Markup Language (HTML) is a language that web pages are created in. HTML isn't a programming language, like Python — instead, it's a markup language that tells a browser how to layout content. HTML allows you to do similar things to what you do in a word processor like Microsoft Word — make text bold, create paragraphs, and so on. Because HTML isn't a programming language, it isn't nearly as complex as Python.\n",
    "\n",
    "Let's take a quick tour through HTML so we know enough to scrape effectively. HTML consists of elements called tags. The most basic tag is the `<html>` tag. This tag tells the web browser that everything inside of it is HTML. We can make a simple HTML document just using this tag:\n",
    "\n",
    "```\n",
    "<html>\n",
    "</html>\n",
    "```\n",
    "Right inside an `html` tag, we put two other tags, the `head` tag, and the `body` tag. The main content of the web page goes into the `body` tag. The `head` tag contains data about the title of the page, and other information that generally isn't useful in web scraping:\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "You may have noticed above that we put the `head` and `body` tags inside the `html` tag. In HTML, tags are nested, and can go inside other tags.\n",
    "\n",
    "We'll now add our first content to the page, in the form of the `p` tag. The `p` tag defines a paragraph, and any text inside the tag is shown as a separate paragraph:\n",
    "\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "<p>\n",
    "Here's a paragraph of text!\n",
    "</p>\n",
    "<p>\n",
    "Here's a second paragraph of text!\n",
    "</p>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "Tags have commonly used names that depend on their position in relation to other tags:\n",
    "\n",
    "+ child — a child is a tag inside another tag. So the two `p` tags above are both children of the `body` tag.\n",
    "+ parent — a parent is the tag another tag is inside. Above, the `html` tag is the parent of the `body` tag.\n",
    "+ sibiling — a sibiling is a tag that is nested inside the same parent as another tag. For example, `head` and `body` are siblings, since they're both inside `html`. Both `p` tags are siblings, since they're both inside `body`.\n",
    "\n",
    "We can also add properties to HTML tags that change their behavior:\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "<p>\n",
    "Here's a paragraph of text!\n",
    "<a href=\"https://www.dataquest.io\">Learn Data Science Online</a>\n",
    "</p>\n",
    "<p>\n",
    "Here's a second paragraph of text!\n",
    "<a href=\"https://www.python.org\">Python</a> </p>\n",
    "</body></html>\n",
    "```\n",
    "In the above example, we added two `a` tags. `a` tags are links, and tell the browser to render a link to another web page. The `href` property of the tag determines where the link goes.\n",
    "\n",
    "`a` and `p` are extremely common html tags. Here are a few others:\n",
    "\n",
    "+ div — indicates a division, or area, of the page.\n",
    "+ b — bolds any text inside.\n",
    "+ i — italicizes any text inside.\n",
    "+ table — creates a table.\n",
    "+ form — creates an input form.\n",
    "\n",
    "For a full list of tags, look [here](https://developer.mozilla.org/en-US/docs/Web/HTML/Element).\n",
    "\n",
    "Before we move into actual web scraping, let's learn about the class and id properties. These special properties give HTML elements names, and make them easier to interact with when we're scraping. One element can have multiple classes, and a class can be shared between elements. Each element can only have one id, and an id can only be used once on a page. Classes and ids are optional, and not all elements will have them.\n",
    "\n",
    "We can add classes and ids to our example:\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "<p class=\"bold-paragraph\">\n",
    "Here's a paragraph of text!\n",
    "<a href=\"https://www.dataquest.io\" id=\"learn-link\">Learn Data Science Online</a>\n",
    "</p>\n",
    "<p class=\"bold-paragraph extra-large\">\n",
    "Here's a second paragraph of text!\n",
    "<a href=\"https://www.python.org\" class=\"extra-large\">Python</a>\n",
    "</p>\n",
    "</body>\n",
    "</html>\n",
    "```\n",
    "As you can see, adding classes and ids doesn't change how the tags are rendered at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The requests library\n",
    "\n",
    "The first thing we'll need to do to scrape a web page is to download the page. We can download pages using the Python [requests library](https://2.python-requests.org//en/master/). The requests library will make a `GET` request to a web server, which will download the HTML contents of a given web page for us.\n",
    "\n",
    "Let's try downloading a simple sample website, http://dataquestio.github.io/web-scraping-pages/simple.html. We'll need to first download it using the `requests.get` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/simple.html\")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running our request, we get a `Response` object. This object has a `status_code` property, which indicates if the page was downloaded successfully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `status_code` of `200` means that the page downloaded successfully. We won't fully dive into status codes here, but a status code starting with a 2 generally indicates success, and a code starting with a 4 or a 5 indicates an error.\n",
    "\n",
    "We can print out the HTML content of the page using the content property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html>\\n    <head>\\n        <title>A simple example page</title>\\n    </head>\\n    <body>\\n        <p>Here is some simple content for this page.</p>\\n    </body>\\n</html>'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing a page with BeautifulSoup\n",
    "\n",
    "As you can see above, we now have downloaded an HTML document.\n",
    "\n",
    "We can use the `BeautifulSoup` library to parse this document, and extract the text from the `p` tag. We first have to import the library, and create an instance of the `BeautifulSoup` class to parse our document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out the HTML content of the page, formatted nicely, using the `prettify` method on the `BeautifulSoup` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   A simple example page\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p>\n",
      "   Here is some simple content for this page.\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As all the tags are nested, we can move through the structure one level at a time. We can first select all the elements at the top level of the page using the `children` property of `soup`. Note that children returns a list generator, so we need to call the `list` function on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['html', '\\n', <html>\n",
       " <head>\n",
       " <title>A simple example page</title>\n",
       " </head>\n",
       " <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>\n",
       " </html>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tells us that there are two tags at the top level of the page — the initial `<!DOCTYPE html>` tag, and the `<html>` tag. There is a newline character (`\\n`) in the list as well. Let's see what the type of each element in the list is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.Doctype, bs4.element.NavigableString, bs4.element.Tag]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(item) for item in list(soup.children)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, all of the items are `BeautifulSoup` objects. The first is a `Doctype` object, which contains information about the type of the document. The second is a `NavigableString`, which represents text found in the HTML document. The final item is a `Tag` object, which contains other nested tags. The most important object type, and the one we'll deal with most often, is the `Tag` object.\n",
    "\n",
    "The `Tag` object allows us to navigate through an HTML document, and extract other tags and text. You can learn more about the various `BeautifulSoup` objects [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#kinds-of-objects).\n",
    "\n",
    "We can now select the `html` tag and its children by taking the third item in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = list(soup.children)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each item in the list returned by the children property is also a `BeautifulSoup` object, so we can also call the `children` method on `html`.\n",
    "\n",
    "Now, we can find the children inside the `html` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <head>\n",
       " <title>A simple example page</title>\n",
       " </head>, '\\n', <body>\n",
       " <p>Here is some simple content for this page.</p>\n",
       " </body>, '\\n']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(html.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, there are two tags here, `head`, and `body`. We want to extract the text inside the `p` tag, so we'll dive into the `body`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = list(html.children)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can get the `p` tag by finding the children of the `body` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', <p>Here is some simple content for this page.</p>, '\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(body.children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now isolate the `p` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(body.children)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've isolated the tag, we can use the `get_text` method to extract all of the text inside the tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding all instances of a tag at once\n",
    "\n",
    "What we did above was useful for figuring out how to navigate a page, but it took a lot of commands to do something fairly simple. If we want to extract a single tag, we can instead use the `find_all` method, which will find all the instances of a tag on a page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Here is some simple content for this page.</p>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `find_all` returns a list, so we’ll have to loop through, or use list indexing, it to extract text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here is some simple content for this page.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you instead only want to find the first instance of a tag, you can use the `find` method, which will return a single `BeautifulSoup` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Here is some simple content for this page.</p>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Searching for tags by class and id\n",
    "\n",
    "We introduced classes and ids earlier, but it probably wasn't clear why they were useful. Classes and ids are used by CSS to determine which HTML elements to apply certain styles to. We can also use them when scraping to specify specific elements we want to scrape. To illustrate this principle, we'll work with the following page:\n",
    "```\n",
    "<html>\n",
    "<head>\n",
    "<title>A simple example page</title>\n",
    "</head>\n",
    "<body>\n",
    "<div>\n",
    "<p class=\"inner-text first-item\" id=\"first\">\n",
    "First paragraph.\n",
    "</p>\n",
    "<p class=\"inner-text\">\n",
    "Second paragraph.\n",
    "</p>\n",
    "</div>\n",
    "<p class=\"outer-text first-item\" id=\"second\">\n",
    "<b>\n",
    "First outer paragraph.\n",
    "</b>\n",
    "</p>\n",
    "<p class=\"outer-text\">\n",
    "<b>\n",
    "Second outer paragraph.\n",
    "</b>\n",
    "</p>\n",
    "</body>\n",
    "</html>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the above document at the URL http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html. Let's first download the page and create a `BeautifulSoup` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<title>A simple example page</title>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "<p class=\"inner-text first-item\" id=\"first\">\n",
       "                First paragraph.\n",
       "            </p>\n",
       "<p class=\"inner-text\">\n",
       "                Second paragraph.\n",
       "            </p>\n",
       "</div>\n",
       "<p class=\"outer-text first-item\" id=\"second\">\n",
       "<b>\n",
       "                First outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "<p class=\"outer-text\">\n",
       "<b>\n",
       "                Second outer paragraph.\n",
       "            </b>\n",
       "</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page = requests.get(\"http://dataquestio.github.io/web-scraping-pages/ids_and_classes.html\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the `find_all` method to search for items by `class` or by `id`. In the below example, we'll search for any `p` tag that has the class `outer-text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p', class_='outer-text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below example, we'll look for any tag that has the class `outer-text`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"outer-text first-item\" id=\"second\">\n",
       " <b>\n",
       "                 First outer paragraph.\n",
       "             </b>\n",
       " </p>, <p class=\"outer-text\">\n",
       " <b>\n",
       "                 Second outer paragraph.\n",
       "             </b>\n",
       " </p>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(class_=\"outer-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also search for elements by `id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id=\"first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using CSS Selectors\n",
    "\n",
    "You can also search for items using CSS selectors. These selectors are how the CSS language allows developers to specify HTML tags to style. Here are some examples:\n",
    "\n",
    "+ `p a` — finds all `a` tags inside of a `p` tag.\n",
    "+ `body p a` — finds all `a` tags inside of a `p` tag inside of a `body` tag.\n",
    "+ `html body` — finds all `body` tags inside of an `html` tag.\n",
    "+ `p.outer-text` — finds all `p` tags with a class of `outer-text`.\n",
    "+ `p#first` — finds all `p` tags with an id of `first`.\n",
    "+ `body p.outer-text` — finds any `p` tags with a class of `outer-text` inside of a `body` tag.\n",
    "\n",
    "You can learn more about CSS selectors [here](https://developer.mozilla.org/en-US/docs/Learn/CSS/Building_blocks/Selectors).\n",
    "\n",
    "`BeautifulSoup` objects support searching a page via CSS selectors using the `select` method. We can use CSS selectors to find all the `p` tags in our page that are inside of a `div` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p class=\"inner-text first-item\" id=\"first\">\n",
       "                 First paragraph.\n",
       "             </p>, <p class=\"inner-text\">\n",
       "                 Second paragraph.\n",
       "             </p>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `select` method above returns a list of `BeautifulSoup` objects, just like `find` and `find_all`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "We now know enough to download a page and start parsing it. In the below code, we:\n",
    "\n",
    "+ Download the web page containing the forecast.\n",
    "+ Create a `BeautifulSoup` class to parse the page.\n",
    "+ Find the `div` with id `seven-day-forecast`, and assign to `seven_day`\n",
    "+ Inside `seven_day`, find each individual forecast item.\n",
    "+ Extract and print the first forecast item.\n",
    "\n",
    "https://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168#.XX-KXH--nIU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"tombstone-container\">\n",
      " <p class=\"period-name\">\n",
      "  Today\n",
      "  <br/>\n",
      "  <br/>\n",
      " </p>\n",
      " <p>\n",
      "  <img alt=\"Today: Rain likely, mainly before 8am.  Cloudy through mid morning, then gradual clearing, with a high near 69. West wind 6 to 15 mph, with gusts as high as 20 mph.  Chance of precipitation is 60%. New precipitation amounts of less than a tenth of an inch possible. \" class=\"forecast-icon\" src=\"DualImage.php?i=ra&amp;j=few&amp;ip=60\" title=\"Today: Rain likely, mainly before 8am.  Cloudy through mid morning, then gradual clearing, with a high near 69. West wind 6 to 15 mph, with gusts as high as 20 mph.  Chance of precipitation is 60%. New precipitation amounts of less than a tenth of an inch possible. \"/>\n",
      " </p>\n",
      " <p class=\"short-desc\">\n",
      "  Rain Likely\n",
      "  <br/>\n",
      "  then Sunny\n",
      " </p>\n",
      " <p class=\"temp temp-high\">\n",
      "  High: 69 °F\n",
      " </p>\n",
      "</div>\n"
     ]
    }
   ],
   "source": [
    "page = requests.get(\"http://forecast.weather.gov/MapClick.php?lat=37.7772&lon=-122.4168\")\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "seven_day = soup.find(id=\"seven-day-forecast\")\n",
    "forecast_items = seven_day.find_all(class_=\"tombstone-container\")\n",
    "tonight = forecast_items[0]\n",
    "print(tonight.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, inside the forecast item tonight is all the information we want. There are 4 pieces of information we can extract:\n",
    "\n",
    "+ The name of the forecast item — in this case, Tonight.\n",
    "+ The description of the conditions — this is stored in the title property of img.\n",
    "+ A short description of the conditions — in this case, Rain Likely.\n",
    "+ The temperature high — in this case, 69 degrees.\n",
    "\n",
    "We'll extract the name of the forecast item, the short description, and the temperature first, since they're all similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today\n",
      "Rain Likelythen Sunny\n",
      "High: 69 °F\n"
     ]
    }
   ],
   "source": [
    "period = tonight.find(class_=\"period-name\").get_text()\n",
    "short_desc = tonight.find(class_=\"short-desc\").get_text()\n",
    "temp = tonight.find(class_=\"temp\").get_text()\n",
    "print(period)\n",
    "print(short_desc)\n",
    "print(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract the title attribute from the `img` tag. To do this, we just treat the `BeautifulSoup` object like a dictionary, and pass in the attribute we want as a key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today: Rain likely, mainly before 8am.  Cloudy through mid morning, then gradual clearing, with a high near 69. West wind 6 to 15 mph, with gusts as high as 20 mph.  Chance of precipitation is 60%. New precipitation amounts of less than a tenth of an inch possible. \n"
     ]
    }
   ],
   "source": [
    "img = tonight.find(\"img\")\n",
    "desc = img['title']\n",
    "print(desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to extract each individual piece of information, we can combine our knowledge with css selectors and list comprehensions to extract everything at once.\n",
    "\n",
    "In the below code, we:\n",
    "\n",
    "+ Select all items with the class `period-name` inside an item with the class `tombstone-container` in `seven_day`.\n",
    "+ Use a list comprehension to call the `get_text` method on each `BeautifulSoup` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Today',\n",
       " 'Tonight',\n",
       " 'Tuesday',\n",
       " 'TuesdayNight',\n",
       " 'Wednesday',\n",
       " 'WednesdayNight',\n",
       " 'Thursday',\n",
       " 'ThursdayNight',\n",
       " 'Friday']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_tags = seven_day.select(\".tombstone-container .period-name\")\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "periods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, our technique gets us each of the period names, in order. We can apply the same technique to get the other 3 fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rain Likelythen Sunny', 'Partly Cloudy', 'Sunny', 'IncreasingClouds', 'Partly Sunny', 'Mostly Clear', 'Sunny', 'Clear', 'Sunny']\n",
      "['High: 69 °F', 'Low: 57 °F', 'High: 71 °F', 'Low: 59 °F', 'High: 69 °F', 'Low: 57 °F', 'High: 71 °F', 'Low: 58 °F', 'High: 75 °F']\n",
      "['Today: Rain likely, mainly before 8am.  Cloudy through mid morning, then gradual clearing, with a high near 69. West wind 6 to 15 mph, with gusts as high as 20 mph.  Chance of precipitation is 60%. New precipitation amounts of less than a tenth of an inch possible. ', 'Tonight: Partly cloudy, with a low around 57. West wind 8 to 16 mph, with gusts as high as 21 mph. ', 'Tuesday: Sunny, with a high near 71. Light and variable wind becoming west 9 to 14 mph in the afternoon. ', 'Tuesday Night: Increasing clouds, with a low around 59. West wind 8 to 15 mph, with gusts as high as 20 mph. ', 'Wednesday: Partly sunny, with a high near 69. West wind 5 to 15 mph, with gusts as high as 20 mph. ', 'Wednesday Night: Mostly clear, with a low around 57.', 'Thursday: Sunny, with a high near 71.', 'Thursday Night: Clear, with a low around 58.', 'Friday: Sunny, with a high near 75.']\n"
     ]
    }
   ],
   "source": [
    "short_descs = [sd.get_text() for sd in seven_day.select(\".tombstone-container .short-desc\")]\n",
    "temps = [t.get_text() for t in seven_day.select(\".tombstone-container .temp\")]\n",
    "descs = [d[\"title\"] for d in seven_day.select(\".tombstone-container img\")]\n",
    "print(short_descs)\n",
    "print(temps)\n",
    "print(descs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A teaser for a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period</th>\n",
       "      <th>short_desc</th>\n",
       "      <th>temp</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Rain Likelythen Sunny</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Today: Rain likely, mainly before 8am.  Cloudy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Tonight: Partly cloudy, with a low around 57. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Tuesday: Sunny, with a high near 71. Light and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TuesdayNight</td>\n",
       "      <td>IncreasingClouds</td>\n",
       "      <td>Low: 59 °F</td>\n",
       "      <td>Tuesday Night: Increasing clouds, with a low a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Partly Sunny</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Wednesday: Partly sunny, with a high near 69. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>Low: 57 °F</td>\n",
       "      <td>Wednesday Night: Mostly clear, with a low arou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 71 °F</td>\n",
       "      <td>Thursday: Sunny, with a high near 71.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "      <td>Thursday Night: Clear, with a low around 58.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>High: 75 °F</td>\n",
       "      <td>Friday: Sunny, with a high near 75.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           period             short_desc         temp  \\\n",
       "0           Today  Rain Likelythen Sunny  High: 69 °F   \n",
       "1         Tonight          Partly Cloudy   Low: 57 °F   \n",
       "2         Tuesday                  Sunny  High: 71 °F   \n",
       "3    TuesdayNight       IncreasingClouds   Low: 59 °F   \n",
       "4       Wednesday           Partly Sunny  High: 69 °F   \n",
       "5  WednesdayNight           Mostly Clear   Low: 57 °F   \n",
       "6        Thursday                  Sunny  High: 71 °F   \n",
       "7   ThursdayNight                  Clear   Low: 58 °F   \n",
       "8          Friday                  Sunny  High: 75 °F   \n",
       "\n",
       "                                                desc  \n",
       "0  Today: Rain likely, mainly before 8am.  Cloudy...  \n",
       "1  Tonight: Partly cloudy, with a low around 57. ...  \n",
       "2  Tuesday: Sunny, with a high near 71. Light and...  \n",
       "3  Tuesday Night: Increasing clouds, with a low a...  \n",
       "4  Wednesday: Partly sunny, with a high near 69. ...  \n",
       "5  Wednesday Night: Mostly clear, with a low arou...  \n",
       "6              Thursday: Sunny, with a high near 71.  \n",
       "7       Thursday Night: Clear, with a low around 58.  \n",
       "8                Friday: Sunny, with a high near 75.  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "    \"period\": periods,\n",
    "    \"short_desc\": short_descs,\n",
    "    \"temp\": temps,\n",
    "    \"desc\":descs\n",
    "})\n",
    "weather"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
